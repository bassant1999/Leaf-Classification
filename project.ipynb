{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "dataset that is used here is https://www.kaggle.com/c/leaf-classification/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import keras_tuner as kt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset, visualize the data, and describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1575</td>\n",
       "      <td>Magnolia_Salicifolia</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.119140</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148440</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1578</td>\n",
       "      <td>Acer_Pictum</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.107420</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1581</td>\n",
       "      <td>Alnus_Maximowiczii</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1582</td>\n",
       "      <td>Quercus_Rubra</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1584</td>\n",
       "      <td>Quercus_Afares</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                species   margin1   margin2   margin3   margin4  \\\n",
       "0       1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1       2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2       3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "3       5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
       "4       6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
       "..    ...                    ...       ...       ...       ...       ...   \n",
       "985  1575   Magnolia_Salicifolia  0.060547  0.119140  0.007812  0.003906   \n",
       "986  1578            Acer_Pictum  0.001953  0.003906  0.021484  0.107420   \n",
       "987  1581     Alnus_Maximowiczii  0.001953  0.003906  0.000000  0.021484   \n",
       "988  1582          Quercus_Rubra  0.000000  0.000000  0.046875  0.056641   \n",
       "989  1584         Quercus_Afares  0.023438  0.019531  0.031250  0.015625   \n",
       "\n",
       "      margin5   margin6   margin7  margin8  ...  texture55  texture56  \\\n",
       "0    0.011719  0.009766  0.027344      0.0  ...   0.007812   0.000000   \n",
       "1    0.025391  0.001953  0.019531      0.0  ...   0.000977   0.000000   \n",
       "2    0.003906  0.005859  0.068359      0.0  ...   0.154300   0.000000   \n",
       "3    0.021484  0.019531  0.023438      0.0  ...   0.000000   0.000977   \n",
       "4    0.013672  0.015625  0.005859      0.0  ...   0.096680   0.000000   \n",
       "..        ...       ...       ...      ...  ...        ...        ...   \n",
       "985  0.000000  0.148440  0.017578      0.0  ...   0.242190   0.000000   \n",
       "986  0.001953  0.000000  0.000000      0.0  ...   0.170900   0.000000   \n",
       "987  0.078125  0.003906  0.007812      0.0  ...   0.004883   0.000977   \n",
       "988  0.009766  0.000000  0.000000      0.0  ...   0.083008   0.030273   \n",
       "989  0.005859  0.019531  0.035156      0.0  ...   0.000000   0.000000   \n",
       "\n",
       "     texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0     0.002930   0.002930   0.035156   0.000000   0.000000   0.004883   \n",
       "1     0.000000   0.000977   0.023438   0.000000   0.000000   0.000977   \n",
       "2     0.005859   0.000977   0.007812   0.000000   0.000000   0.000000   \n",
       "3     0.000000   0.000000   0.020508   0.000000   0.000000   0.017578   \n",
       "4     0.021484   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985   0.034180   0.000000   0.010742   0.000000   0.000000   0.000000   \n",
       "986   0.018555   0.000000   0.011719   0.000000   0.000000   0.000977   \n",
       "987   0.004883   0.027344   0.016602   0.007812   0.000000   0.027344   \n",
       "988   0.000977   0.002930   0.014648   0.000000   0.041992   0.000000   \n",
       "989   0.002930   0.000000   0.012695   0.000000   0.000000   0.023438   \n",
       "\n",
       "     texture63  texture64  \n",
       "0     0.000000   0.025391  \n",
       "1     0.039062   0.022461  \n",
       "2     0.020508   0.002930  \n",
       "3     0.000000   0.047852  \n",
       "4     0.000000   0.031250  \n",
       "..         ...        ...  \n",
       "985   0.000000   0.018555  \n",
       "986   0.000000   0.021484  \n",
       "987   0.000000   0.001953  \n",
       "988   0.001953   0.002930  \n",
       "989   0.025391   0.022461  \n",
       "\n",
       "[990 rows x 194 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "path = 'train.csv'\n",
    "df = read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1575</td>\n",
       "      <td>Magnolia_Salicifolia</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.119140</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148440</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1578</td>\n",
       "      <td>Acer_Pictum</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.107420</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1581</td>\n",
       "      <td>Alnus_Maximowiczii</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1582</td>\n",
       "      <td>Quercus_Rubra</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1584</td>\n",
       "      <td>Quercus_Afares</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                species   margin1   margin2   margin3   margin4  \\\n",
       "0       1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1       2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2       3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "3       5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
       "4       6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
       "..    ...                    ...       ...       ...       ...       ...   \n",
       "985  1575   Magnolia_Salicifolia  0.060547  0.119140  0.007812  0.003906   \n",
       "986  1578            Acer_Pictum  0.001953  0.003906  0.021484  0.107420   \n",
       "987  1581     Alnus_Maximowiczii  0.001953  0.003906  0.000000  0.021484   \n",
       "988  1582          Quercus_Rubra  0.000000  0.000000  0.046875  0.056641   \n",
       "989  1584         Quercus_Afares  0.023438  0.019531  0.031250  0.015625   \n",
       "\n",
       "      margin5   margin6   margin7  margin8  ...  texture55  texture56  \\\n",
       "0    0.011719  0.009766  0.027344      0.0  ...   0.007812   0.000000   \n",
       "1    0.025391  0.001953  0.019531      0.0  ...   0.000977   0.000000   \n",
       "2    0.003906  0.005859  0.068359      0.0  ...   0.154300   0.000000   \n",
       "3    0.021484  0.019531  0.023438      0.0  ...   0.000000   0.000977   \n",
       "4    0.013672  0.015625  0.005859      0.0  ...   0.096680   0.000000   \n",
       "..        ...       ...       ...      ...  ...        ...        ...   \n",
       "985  0.000000  0.148440  0.017578      0.0  ...   0.242190   0.000000   \n",
       "986  0.001953  0.000000  0.000000      0.0  ...   0.170900   0.000000   \n",
       "987  0.078125  0.003906  0.007812      0.0  ...   0.004883   0.000977   \n",
       "988  0.009766  0.000000  0.000000      0.0  ...   0.083008   0.030273   \n",
       "989  0.005859  0.019531  0.035156      0.0  ...   0.000000   0.000000   \n",
       "\n",
       "     texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0     0.002930   0.002930   0.035156   0.000000   0.000000   0.004883   \n",
       "1     0.000000   0.000977   0.023438   0.000000   0.000000   0.000977   \n",
       "2     0.005859   0.000977   0.007812   0.000000   0.000000   0.000000   \n",
       "3     0.000000   0.000000   0.020508   0.000000   0.000000   0.017578   \n",
       "4     0.021484   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985   0.034180   0.000000   0.010742   0.000000   0.000000   0.000000   \n",
       "986   0.018555   0.000000   0.011719   0.000000   0.000000   0.000977   \n",
       "987   0.004883   0.027344   0.016602   0.007812   0.000000   0.027344   \n",
       "988   0.000977   0.002930   0.014648   0.000000   0.041992   0.000000   \n",
       "989   0.002930   0.000000   0.012695   0.000000   0.000000   0.023438   \n",
       "\n",
       "     texture63  texture64  \n",
       "0     0.000000   0.025391  \n",
       "1     0.039062   0.022461  \n",
       "2     0.020508   0.002930  \n",
       "3     0.000000   0.047852  \n",
       "4     0.000000   0.031250  \n",
       "..         ...        ...  \n",
       "985   0.000000   0.018555  \n",
       "986   0.000000   0.021484  \n",
       "987   0.000000   0.001953  \n",
       "988   0.001953   0.002930  \n",
       "989   0.025391   0.022461  \n",
       "\n",
       "[990 rows x 194 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove empty cells\n",
    "df.dropna(inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1575</td>\n",
       "      <td>Magnolia_Salicifolia</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.119140</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148440</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1578</td>\n",
       "      <td>Acer_Pictum</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.107420</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1581</td>\n",
       "      <td>Alnus_Maximowiczii</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1582</td>\n",
       "      <td>Quercus_Rubra</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1584</td>\n",
       "      <td>Quercus_Afares</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                species   margin1   margin2   margin3   margin4  \\\n",
       "0       1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1       2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2       3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "3       5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
       "4       6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
       "..    ...                    ...       ...       ...       ...       ...   \n",
       "985  1575   Magnolia_Salicifolia  0.060547  0.119140  0.007812  0.003906   \n",
       "986  1578            Acer_Pictum  0.001953  0.003906  0.021484  0.107420   \n",
       "987  1581     Alnus_Maximowiczii  0.001953  0.003906  0.000000  0.021484   \n",
       "988  1582          Quercus_Rubra  0.000000  0.000000  0.046875  0.056641   \n",
       "989  1584         Quercus_Afares  0.023438  0.019531  0.031250  0.015625   \n",
       "\n",
       "      margin5   margin6   margin7  margin8  ...  texture55  texture56  \\\n",
       "0    0.011719  0.009766  0.027344      0.0  ...   0.007812   0.000000   \n",
       "1    0.025391  0.001953  0.019531      0.0  ...   0.000977   0.000000   \n",
       "2    0.003906  0.005859  0.068359      0.0  ...   0.154300   0.000000   \n",
       "3    0.021484  0.019531  0.023438      0.0  ...   0.000000   0.000977   \n",
       "4    0.013672  0.015625  0.005859      0.0  ...   0.096680   0.000000   \n",
       "..        ...       ...       ...      ...  ...        ...        ...   \n",
       "985  0.000000  0.148440  0.017578      0.0  ...   0.242190   0.000000   \n",
       "986  0.001953  0.000000  0.000000      0.0  ...   0.170900   0.000000   \n",
       "987  0.078125  0.003906  0.007812      0.0  ...   0.004883   0.000977   \n",
       "988  0.009766  0.000000  0.000000      0.0  ...   0.083008   0.030273   \n",
       "989  0.005859  0.019531  0.035156      0.0  ...   0.000000   0.000000   \n",
       "\n",
       "     texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0     0.002930   0.002930   0.035156   0.000000   0.000000   0.004883   \n",
       "1     0.000000   0.000977   0.023438   0.000000   0.000000   0.000977   \n",
       "2     0.005859   0.000977   0.007812   0.000000   0.000000   0.000000   \n",
       "3     0.000000   0.000000   0.020508   0.000000   0.000000   0.017578   \n",
       "4     0.021484   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985   0.034180   0.000000   0.010742   0.000000   0.000000   0.000000   \n",
       "986   0.018555   0.000000   0.011719   0.000000   0.000000   0.000977   \n",
       "987   0.004883   0.027344   0.016602   0.007812   0.000000   0.027344   \n",
       "988   0.000977   0.002930   0.014648   0.000000   0.041992   0.000000   \n",
       "989   0.002930   0.000000   0.012695   0.000000   0.000000   0.023438   \n",
       "\n",
       "     texture63  texture64  \n",
       "0     0.000000   0.025391  \n",
       "1     0.039062   0.022461  \n",
       "2     0.020508   0.002930  \n",
       "3     0.000000   0.047852  \n",
       "4     0.000000   0.031250  \n",
       "..         ...        ...  \n",
       "985   0.000000   0.018555  \n",
       "986   0.000000   0.021484  \n",
       "987   0.000000   0.001953  \n",
       "988   0.001953   0.002930  \n",
       "989   0.025391   0.022461  \n",
       "\n",
       "[990 rows x 194 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates\n",
    "df.drop_duplicates(inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "[0.005859 0.0 0.03125 0.015625 0.025391 0.001953 0.019531 0.0 0.0 0.007812\n",
      " 0.003906 0.027344 0.023438 0.0 0.033203 0.0 0.009766 0.009766 0.007812\n",
      " 0.007812 0.019531 0.007812 0.0 0.0 0.007812 0.027344 0.003906 0.037109\n",
      " 0.007812 0.048828 0.054688 0.027344 0.003906 0.0 0.0 0.003906 0.013672\n",
      " 0.033203 0.033203 0.019531 0.03125 0.009766 0.007812 0.03125 0.001953\n",
      " 0.039062 0.029297 0.03125 0.035156 0.0 0.007812 0.0 0.046875 0.046875\n",
      " 0.029297 0.009766 0.017578 0.007812 0.013672 0.019531 0.0 0.0 0.003906\n",
      " 0.0 0.00074942 0.00069461 0.0007198 0.00070948 0.00068849 0.00066046\n",
      " 0.00062381 0.00058531 0.00055583 0.00053091 0.00050553 0.00048417\n",
      " 0.00046714 0.00045311 0.0004424 0.0004347 0.00043541 0.00043311\n",
      " 0.00044305 0.00046024 0.00047142 0.00048563 0.00051198 0.00053842\n",
      " 0.000567 0.00060459 0.00064376 0.00068698 0.00073141 0.00077748\n",
      " 0.00083219 0.00088429 0.00090166 0.00086166 0.00084172 0.0007829\n",
      " 0.00073129 0.00067913 0.00063886 0.00059633 0.00056019 0.00052754\n",
      " 0.00049597 0.00047412 0.00046162 0.00044696 0.00043426 0.00043348\n",
      " 0.00043533 0.00043631 0.00044743 0.00046355 0.00047893 0.0004963\n",
      " 0.00051774 0.00054563 0.00057398 0.00060783 0.00064104 0.00067412\n",
      " 0.00070265 0.00070739 0.0006884 0.00074675 0.0 0.0 0.007812 0.079102 0.0\n",
      " 0.039062 0.000977 0.0 0.027344 0.003906 0.0 0.0 0.014648 0.041016 0.0 0.0\n",
      " 0.003906 0.0 0.020508 0.006836 0.0 0.001953 0.026367 0.020508 0.050781\n",
      " 0.001953 0.021484 0.003906 0.027344 0.023438 0.0625 0.0 0.038086 0.0\n",
      " 0.019531 0.0 0.001953 0.003906 0.015625 0.004883 0.10449 0.0 0.061523\n",
      " 0.007812 0.008789 0.013672 0.011719 0.001953 0.035156 0.007812 0.0 0.0\n",
      " 0.053711 0.036133 0.000977 0.0 0.0 0.000977 0.023438 0.0 0.0 0.000977\n",
      " 0.039062 0.022461]\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "print(len(df['species'].unique()))\n",
    "print(df.values[:, 2:][1])\n",
    "print(len(df['species'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data description\n",
    "The dataset consists approximately 990 leaf specimens/images, and its features. Three sets of features are also provided per row or image: a shape contiguous descriptor, an interior texture histogram, and a ﬁne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# read image \n",
    "image = cv2.imread('images/1.jpg')\n",
    "# show the image, provide window name first\n",
    "cv2.imshow('image window 1', image)\n",
    "# add wait key. window waits until user presses a key\n",
    "cv2.waitKey(0)\n",
    "# and finally destroy/close all open windows\n",
    "cv2.destroyAllWindows()\n",
    "# read image \n",
    "image = cv2.imread('images/2.jpg')\n",
    "# show the image, provide window name first\n",
    "cv2.imshow('image window 2', image)\n",
    "# add wait key. window waits until user presses a key\n",
    "cv2.waitKey(0)\n",
    "# and finally destroy/close all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot-encoding and spit data into training set, validation set, and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 192)\n",
      "(990,)\n",
      "[0.005859 0.0 0.03125 0.015625 0.025391 0.001953 0.019531 0.0 0.0 0.007812\n",
      " 0.003906 0.027344 0.023438 0.0 0.033203 0.0 0.009766 0.009766 0.007812\n",
      " 0.007812 0.019531 0.007812 0.0 0.0 0.007812 0.027344 0.003906 0.037109\n",
      " 0.007812 0.048828 0.054688 0.027344 0.003906 0.0 0.0 0.003906 0.013672\n",
      " 0.033203 0.033203 0.019531 0.03125 0.009766 0.007812 0.03125 0.001953\n",
      " 0.039062 0.029297 0.03125 0.035156 0.0 0.007812 0.0 0.046875 0.046875\n",
      " 0.029297 0.009766 0.017578 0.007812 0.013672 0.019531 0.0 0.0 0.003906\n",
      " 0.0 0.00074942 0.00069461 0.0007198 0.00070948 0.00068849 0.00066046\n",
      " 0.00062381 0.00058531 0.00055583 0.00053091 0.00050553 0.00048417\n",
      " 0.00046714 0.00045311 0.0004424 0.0004347 0.00043541 0.00043311\n",
      " 0.00044305 0.00046024 0.00047142 0.00048563 0.00051198 0.00053842\n",
      " 0.000567 0.00060459 0.00064376 0.00068698 0.00073141 0.00077748\n",
      " 0.00083219 0.00088429 0.00090166 0.00086166 0.00084172 0.0007829\n",
      " 0.00073129 0.00067913 0.00063886 0.00059633 0.00056019 0.00052754\n",
      " 0.00049597 0.00047412 0.00046162 0.00044696 0.00043426 0.00043348\n",
      " 0.00043533 0.00043631 0.00044743 0.00046355 0.00047893 0.0004963\n",
      " 0.00051774 0.00054563 0.00057398 0.00060783 0.00064104 0.00067412\n",
      " 0.00070265 0.00070739 0.0006884 0.00074675 0.0 0.0 0.007812 0.079102 0.0\n",
      " 0.039062 0.000977 0.0 0.027344 0.003906 0.0 0.0 0.014648 0.041016 0.0 0.0\n",
      " 0.003906 0.0 0.020508 0.006836 0.0 0.001953 0.026367 0.020508 0.050781\n",
      " 0.001953 0.021484 0.003906 0.027344 0.023438 0.0625 0.0 0.038086 0.0\n",
      " 0.019531 0.0 0.001953 0.003906 0.015625 0.004883 0.10449 0.0 0.061523\n",
      " 0.007812 0.008789 0.013672 0.011719 0.001953 0.035156 0.007812 0.0 0.0\n",
      " 0.053711 0.036133 0.000977 0.0 0.0 0.000977 0.023438 0.0 0.0 0.000977\n",
      " 0.039062 0.022461]\n",
      "Pterocarya_Stenoptera\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# split into input and output columns\n",
    "X, y = df.values[:, 2:], df['species'].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[1])\n",
    "print(y[1])\n",
    "X = X.astype('float64') # ensure all data are floating point values\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "print(y[1])\n",
    "# y_one_hot_encoding = LabelBinarizer().fit_transform(y)\n",
    "# print(y_one_hot_encoding.shape)\n",
    "# print(y_one_hot_encoding[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- Normalization\n",
    "- Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 192) (198, 192) (594,) (198,) (198, 192) (198,)\n",
      "(594, 192) (198, 192) (594,) (198,) (198, 192) (198,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train validation, and test datasets\n",
    "#\n",
    "xrest, X_test, yrest, y_test = train_test_split(X, y, test_size=0.2,train_size=0.8 , shuffle = True , random_state=42)\n",
    "X_train, xval, y_train, yval = train_test_split(xrest,yrest,test_size = 0.25,train_size =0.75 , shuffle = True , random_state=42)\n",
    "\n",
    "#\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, xval.shape, yval.shape)\n",
    "\n",
    "# normalization\n",
    "# mean = 0 ; standard deviation = 1.0\n",
    "scaler = preprocessing.StandardScaler() # we estimated the mean and varience of the training set, and divide by train set to make mean = 0 ; standard deviation = 1.0\n",
    "X_train = scaler.fit_transform(X_train) # we use the same estimation to test set\n",
    "X_test = scaler.transform(X_test)\n",
    "xval = scaler.transform(xval)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 99\n"
     ]
    }
   ],
   "source": [
    "# determine the number of input features\n",
    "n_features = X_train.shape[1] # X_train.shape[0] is no. of training samples, and X_train.shape[1] is no. of features in training sample\n",
    "n_classes = len(np.unique(df['species'].values))\n",
    "print(n_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 192) (198, 192) (594, 99) (198, 99) (198, 192) (198, 99)\n"
     ]
    }
   ],
   "source": [
    "# one-hot-encoding\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "y_train=to_categorical(y_train,n_classes)\n",
    "y_test=to_categorical(y_test,n_classes)\n",
    "yval=to_categorical(yval,n_classes)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id   margin1   margin2   margin3   margin4   margin5  \\\n",
      "id         1.000000 -0.011673 -0.027565 -0.059533  0.001639 -0.002419   \n",
      "margin1   -0.011673  1.000000  0.806390 -0.182829 -0.297807 -0.475874   \n",
      "margin2   -0.027565  0.806390  1.000000 -0.204640 -0.315953 -0.444312   \n",
      "margin3   -0.059533 -0.182829 -0.204640  1.000000  0.120042 -0.185007   \n",
      "margin4    0.001639 -0.297807 -0.315953  0.120042  1.000000  0.029480   \n",
      "...             ...       ...       ...       ...       ...       ...   \n",
      "texture60 -0.000823  0.035072  0.081069 -0.019850 -0.052317  0.006542   \n",
      "texture61  0.026319 -0.007581 -0.007057  0.084957  0.320644 -0.109229   \n",
      "texture62  0.032873 -0.033159 -0.037405 -0.081999 -0.073886  0.151675   \n",
      "texture63  0.024299 -0.075171 -0.098957 -0.148193  0.050970  0.022299   \n",
      "texture64  0.035396  0.030414 -0.029532  0.061780  0.014343 -0.148834   \n",
      "\n",
      "            margin6   margin7   margin8   margin9  ...  texture55  texture56  \\\n",
      "id        -0.051818  0.061214 -0.039509 -0.070954  ...  -0.040292  -0.005132   \n",
      "margin1    0.767718  0.066273 -0.094137 -0.181496  ...   0.137158  -0.047771   \n",
      "margin2    0.825762 -0.083273 -0.086428 -0.120276  ...   0.154407  -0.021096   \n",
      "margin3   -0.163976  0.095449  0.024350 -0.000042  ...   0.047347  -0.027618   \n",
      "margin4   -0.261437 -0.268271 -0.047693  0.227543  ...  -0.071974  -0.009537   \n",
      "...             ...       ...       ...       ...  ...        ...        ...   \n",
      "texture60  0.066262 -0.034094  0.048647 -0.028292  ...  -0.129365   0.004412   \n",
      "texture61 -0.050498 -0.163375 -0.079283  0.088517  ...  -0.002235   0.053707   \n",
      "texture62 -0.031555  0.015391 -0.048843 -0.031954  ...  -0.217239   0.171577   \n",
      "texture63 -0.132087 -0.001364  0.027758 -0.119494  ...  -0.207887   0.002057   \n",
      "texture64 -0.003164  0.068512 -0.003191 -0.097760  ...  -0.095205  -0.095913   \n",
      "\n",
      "           texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
      "id         -0.043101   0.063337  -0.007915  -0.000823   0.026319   0.032873   \n",
      "margin1     0.126227  -0.024139  -0.168201   0.035072  -0.007581  -0.033159   \n",
      "margin2     0.123834  -0.063654  -0.157842   0.081069  -0.007057  -0.037405   \n",
      "margin3     0.007261  -0.021390   0.033505  -0.019850   0.084957  -0.081999   \n",
      "margin4    -0.050529  -0.044318   0.088857  -0.052317   0.320644  -0.073886   \n",
      "...              ...        ...        ...        ...        ...        ...   \n",
      "texture60  -0.155187   0.240704  -0.183369   1.000000  -0.051838   0.265879   \n",
      "texture61  -0.072814  -0.084638  -0.023539  -0.051838   1.000000  -0.063582   \n",
      "texture62  -0.283316   0.563088  -0.128010   0.265879  -0.063582   1.000000   \n",
      "texture63  -0.064724  -0.059866   0.156568  -0.089679  -0.068065  -0.058189   \n",
      "texture64   0.224686  -0.269157  -0.015374  -0.190194   0.036374  -0.245527   \n",
      "\n",
      "           texture63  texture64  \n",
      "id          0.024299   0.035396  \n",
      "margin1    -0.075171   0.030414  \n",
      "margin2    -0.098957  -0.029532  \n",
      "margin3    -0.148193   0.061780  \n",
      "margin4     0.050970   0.014343  \n",
      "...              ...        ...  \n",
      "texture60  -0.089679  -0.190194  \n",
      "texture61  -0.068065   0.036374  \n",
      "texture62  -0.058189  -0.245527  \n",
      "texture63   1.000000   0.029305  \n",
      "texture64   0.029305   1.000000  \n",
      "\n",
      "[193 rows x 193 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no much correlation between certain column and the other columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((594, 99), (594, 192))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 2s 5ms/step - loss: 4.5362 - categorical_accuracy: 0.0505 \n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 3.1434 - categorical_accuracy: 0.4343\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 2.2554 - categorical_accuracy: 0.6919\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.6425 - categorical_accuracy: 0.7980\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1954 - categorical_accuracy: 0.8838\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8973 - categorical_accuracy: 0.9242\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6754 - categorical_accuracy: 0.9697\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5191 - categorical_accuracy: 0.9949\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4021 - categorical_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3143 - categorical_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2517 - categorical_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2073 - categorical_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1745 - categorical_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1485 - categorical_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1295 - categorical_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1136 - categorical_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1009 - categorical_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0902 - categorical_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0815 - categorical_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0741 - categorical_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0680 - categorical_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0626 - categorical_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0578 - categorical_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0536 - categorical_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0497 - categorical_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0465 - categorical_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0437 - categorical_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0411 - categorical_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0387 - categorical_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0365 - categorical_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0345 - categorical_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0329 - categorical_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0312 - categorical_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0296 - categorical_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0283 - categorical_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0270 - categorical_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0257 - categorical_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0246 - categorical_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0236 - categorical_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0227 - categorical_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0218 - categorical_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0210 - categorical_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0201 - categorical_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0194 - categorical_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0187 - categorical_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0180 - categorical_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0174 - categorical_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0168 - categorical_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0163 - categorical_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0158 - categorical_accuracy: 1.0000\n",
      "Best: 0.575758 using {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.046836) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.043446) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.044605) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.037113) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.063484) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.560606 (0.049485) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.049485) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.025753) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.046836) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.043446) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.046836) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.037113) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.035712) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.049997) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.037795) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.055785) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.046836) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.046836) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.053925) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.063484) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.049997) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.062267) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.575758 (0.037113) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.032731) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.025753) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.068135) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.043446) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.012371) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.049997) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.061025) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.039768) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.049997) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.031133) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.049997) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.063484) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.055785) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.063484) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.051505) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.051505) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.032731) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.560606 (0.037113) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.049485) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.044605) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.049997) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.025753) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.037113) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.058464) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.570707 (0.051505) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.035712) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.037795) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.037795) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.031133) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.032731) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.049997) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.454545 (0.037113) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.025753) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.063484) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.044605) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.037795) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.042855) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.094486) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.474747 (0.039768) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.056692) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.032731) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.068135) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.043446) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.044605) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.037113) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.051505) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.031133) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.051505) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.065462) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.053925) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.035712) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.051505) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.039768) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.046836) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.064282) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.037113) with: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.042855) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.056692) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.058464) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.046836) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.068135) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.039768) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.057140) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.068135) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.049485) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.031133) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.053925) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.063484) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.051505) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.032731) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.039768) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.032731) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.051505) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.062267) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.049997) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.565657 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.043446) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.565657 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.063484) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.058464) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.053925) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.053925) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.061025) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.046836) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.075251) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.044605) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.039768) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.049997) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.068135) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.037795) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.075251) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.055785) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.043446) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.058464) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.053925) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.560606 (0.049485) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.055785) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.560606 (0.037113) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.046836) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.565657 (0.043446) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.039768) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.039768) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.051505) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.049485) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.075589) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.037113) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.043446) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.051505) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.053925) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.057140) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.061025) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.057140) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535354 (0.049997) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.061025) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.061025) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.070345) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.044605) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.031133) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.018897) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.043446) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.064282) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.049485) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.044605) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.031133) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.053925) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.058464) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.046836) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.056692) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.035712) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.035712) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.056692) with: {'batch_size': 32, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.031133) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.061025) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.068135) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.042855) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.055785) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.469697 (0.065462) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.032731) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.049997) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.474747 (0.028570) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.046836) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.043446) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.043446) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.042855) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.028570) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.062267) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.039768) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.035712) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.018897) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.039768) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.061025) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.032731) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.037795) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.021427) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.565657 (0.049997) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.043446) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.037113) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.570707 (0.051505) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.434343 (0.035712) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.042855) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.049485) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.469697 (0.032731) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.058464) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.042855) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.043446) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.037795) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.058464) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.063484) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.061856) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.044605) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.044605) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.032731) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.025753) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.055785) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.049485) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.032731) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.018897) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.055785) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.028570) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.068135) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.044605) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.044605) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.032731) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.025753) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.419192 (0.046836) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.414141 (0.007142) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.454545 (0.049485) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.393939 (0.044605) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.409091 (0.056692) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.409091 (0.037113) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.444444 (0.028570) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.393939 (0.049485) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.393939 (0.044605) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.037795) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.469697 (0.049485) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.061025) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.049997) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.039768) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.071425) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.464646 (0.043446) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.063484) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.464646 (0.018897) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.039768) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.057140) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.044605) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.051505) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.058464) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.068880) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.053925) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.044605) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.056692) with: {'batch_size': 64, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.028570) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.064282) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.025753) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.044605) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.063484) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.044605) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.065462) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.025753) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.056692) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.042855) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.025753) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.061025) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.072488) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.058464) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.057140) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.061025) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.039768) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.051505) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.565657 (0.055785) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.055785) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.039768) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.037795) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.560606 (0.024742) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.042855) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.049997) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.061025) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.053925) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.072488) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.093400) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.053925) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.039768) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.025753) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.025753) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.051505) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.049997) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.039768) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.032731) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.028570) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.051505) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.032731) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.042855) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.049997) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.037113) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.024742) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.065462) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.049485) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.057140) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.570707 (0.039768) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.049997) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.021427) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.051505) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.560606 (0.032731) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.037795) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.049997) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.053925) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.055785) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.042855) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.031133) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.068880) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.055785) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.056692) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.085710) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.018897) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.064282) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.049997) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.037795) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.031133) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.043446) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.062267) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.042855) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.062267) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.031133) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.049997) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.570707 (0.028570) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.031133) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.061025) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.051505) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.049997) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.024742) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.037795) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.072488) with: {'batch_size': 64, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.429293 (0.051505) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.434343 (0.031133) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.434343 (0.037795) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.449495 (0.039768) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.454545 (0.049485) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.464646 (0.025753) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.072488) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.434343 (0.046836) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.419192 (0.007142) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.049997) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.058464) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.043446) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.032731) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.058464) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.025753) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.055785) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.061025) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.018897) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.046836) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.053925) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.051505) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.049997) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.028570) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.037795) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.032731) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.031133) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.042855) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.429293 (0.072488) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.388889 (0.079535) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.404040 (0.046836) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.414141 (0.049997) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.414141 (0.055785) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.363636 (0.012371) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.383838 (0.049997) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.414141 (0.055785) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.388889 (0.007142) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.474747 (0.031133) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.439394 (0.037113) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.454545 (0.074227) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.063484) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.049997) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.046836) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.039768) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.469697 (0.032731) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.061025) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.021427) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.012371) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.049997) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.042855) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.056692) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.075251) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.053925) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.018897) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.077258) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.338384 (0.037795) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.368687 (0.007142) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.353535 (0.043446) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.373737 (0.039768) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.333333 (0.012371) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.358586 (0.031133) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.348485 (0.012371) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.303030 (0.000000) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.343434 (0.037795) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.363636 (0.037113) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.398990 (0.028570) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.409091 (0.065462) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.409091 (0.044605) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.419192 (0.031133) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.414141 (0.039768) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.378788 (0.012371) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.419192 (0.063484) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.363636 (0.042855) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.065462) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.464646 (0.068135) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.449495 (0.035712) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.043446) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.454545 (0.044605) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.469697 (0.042855) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.444444 (0.037795) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.454545 (0.065462) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.439394 (0.044605) with: {'batch_size': 128, 'epochs': 50, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.024742) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.058464) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.071425) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.046836) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.049997) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.510101 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.056692) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.053925) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.018897) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.063484) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.042855) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.025753) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.565657 (0.035712) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.065462) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.039768) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.044605) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.064282) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.055785) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.032731) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.028570) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.555556 (0.018897) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.028570) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.039768) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.018897) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.056692) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.444444 (0.051505) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.500000 (0.049485) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.068135) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.070345) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.464646 (0.051505) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.028570) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.049997) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.032731) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.071425) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.044605) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.061856) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.505051 (0.051505) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.540404 (0.043446) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.046836) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.068135) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.545455 (0.032731) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.550505 (0.028570) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.046836) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.058464) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.039768) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.024742) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.031133) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.535354 (0.051505) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.4, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.454545 (0.065462) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.444444 (0.051505) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.419192 (0.046836) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.469697 (0.037113) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.439394 (0.021427) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.414141 (0.061025) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.444444 (0.051505) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.459596 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.479798 (0.055785) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 128, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.049485) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.484848 (0.044605) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.031133) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.018897) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.039768) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.494949 (0.043446) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.039768) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.489899 (0.075589) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 200, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.053925) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.046836) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.061025) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'SGD', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.520202 (0.043446) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.515152 (0.068880) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.046836) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n",
      "0.530303 (0.044605) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.037795) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.525253 (0.055785) with: {'batch_size': 128, 'epochs': 100, 'model__dropout_rate': 0.7, 'model__neurons': 300, 'optimizer': 'Adam', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "from keras.layers import Dropout\n",
    "def create_model(neurons, dropout_rate, optimizer='adam'):\n",
    "    # create model \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='tanh', input_shape=(n_features,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,  metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(model=create_model, verbose=1)\n",
    "# define the grid search parameters\n",
    "batch_size = [32, 64, 128]\n",
    "epochs = [50, 100]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adam']\n",
    "learn_rate = [0.001, 0.01, 0.0001]\n",
    "momentum = [0.0]\n",
    "dropout_rate = [0.0, 0.4, 0.7]\n",
    "neurons = [128, 200, 300]\n",
    "param_grid = dict(optimizer__learning_rate=learn_rate, optimizer__momentum=momentum, optimizer=optimizer, batch_size=batch_size, epochs=epochs, model__dropout_rate=dropout_rate, model__neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(xval, yval, verbose = 1)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.575758 using {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.0, 'model__neurons': 300, 'optimizer': 'RMSprop', 'optimizer__learning_rate': 0.0001, 'optimizer__momentum': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.0 RMSprop 50 32 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "parameters = grid_result.best_params_\n",
    "nuerons = parameters['model__neurons']\n",
    "dropout_rate = parameters['model__dropout_rate']\n",
    "optimizer = parameters['optimizer']\n",
    "epochs = parameters['epochs']\n",
    "batch_size = parameters['batch_size']\n",
    "print(nuerons, dropout_rate, optimizer, int(epochs), batch_size, type(int(epochs)))\n",
    "model = Sequential()\n",
    "model.add(Dense(int(nuerons), activation='tanh', input_shape=(n_features,)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, activation='tanh', input_shape=(n_features,)))\n",
    "model.add(Dropout(0.0))\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 16ms/step - loss: 0.0045 - categorical_crossentropy: 0.0045 - val_loss: 0.0555 - val_categorical_crossentropy: 0.0555\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - categorical_crossentropy: 0.0044 - val_loss: 0.0551 - val_categorical_crossentropy: 0.0551\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - categorical_crossentropy: 0.0044 - val_loss: 0.0550 - val_categorical_crossentropy: 0.0550\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043 - categorical_crossentropy: 0.0043 - val_loss: 0.0549 - val_categorical_crossentropy: 0.0549\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042 - categorical_crossentropy: 0.0042 - val_loss: 0.0547 - val_categorical_crossentropy: 0.0547\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042 - categorical_crossentropy: 0.0042 - val_loss: 0.0548 - val_categorical_crossentropy: 0.0548\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041 - categorical_crossentropy: 0.0041 - val_loss: 0.0546 - val_categorical_crossentropy: 0.0546\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041 - categorical_crossentropy: 0.0041 - val_loss: 0.0545 - val_categorical_crossentropy: 0.0545\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040 - categorical_crossentropy: 0.0040 - val_loss: 0.0544 - val_categorical_crossentropy: 0.0544\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040 - categorical_crossentropy: 0.0040 - val_loss: 0.0545 - val_categorical_crossentropy: 0.0545\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0039 - categorical_crossentropy: 0.0039 - val_loss: 0.0545 - val_categorical_crossentropy: 0.0545\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039 - categorical_crossentropy: 0.0039 - val_loss: 0.0542 - val_categorical_crossentropy: 0.0542\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0038 - categorical_crossentropy: 0.0038 - val_loss: 0.0542 - val_categorical_crossentropy: 0.0542\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0038 - categorical_crossentropy: 0.0038 - val_loss: 0.0538 - val_categorical_crossentropy: 0.0538\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0037 - categorical_crossentropy: 0.0037 - val_loss: 0.0535 - val_categorical_crossentropy: 0.0535\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0037 - categorical_crossentropy: 0.0037 - val_loss: 0.0534 - val_categorical_crossentropy: 0.0534\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036 - categorical_crossentropy: 0.0036 - val_loss: 0.0534 - val_categorical_crossentropy: 0.0534\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036 - categorical_crossentropy: 0.0036 - val_loss: 0.0532 - val_categorical_crossentropy: 0.0532\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0036 - categorical_crossentropy: 0.0036 - val_loss: 0.0530 - val_categorical_crossentropy: 0.0530\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035 - categorical_crossentropy: 0.0035 - val_loss: 0.0528 - val_categorical_crossentropy: 0.0528\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035 - categorical_crossentropy: 0.0035 - val_loss: 0.0527 - val_categorical_crossentropy: 0.0527\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0034 - categorical_crossentropy: 0.0034 - val_loss: 0.0525 - val_categorical_crossentropy: 0.0525\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0034 - categorical_crossentropy: 0.0034 - val_loss: 0.0525 - val_categorical_crossentropy: 0.0525\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0034 - categorical_crossentropy: 0.0034 - val_loss: 0.0524 - val_categorical_crossentropy: 0.0524\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0033 - categorical_crossentropy: 0.0033 - val_loss: 0.0522 - val_categorical_crossentropy: 0.0522\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0033 - categorical_crossentropy: 0.0033 - val_loss: 0.0520 - val_categorical_crossentropy: 0.0520\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033 - categorical_crossentropy: 0.0033 - val_loss: 0.0519 - val_categorical_crossentropy: 0.0519\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0032 - categorical_crossentropy: 0.0032 - val_loss: 0.0520 - val_categorical_crossentropy: 0.0520\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0032 - categorical_crossentropy: 0.0032 - val_loss: 0.0518 - val_categorical_crossentropy: 0.0518\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0032 - categorical_crossentropy: 0.0032 - val_loss: 0.0517 - val_categorical_crossentropy: 0.0517\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0031 - categorical_crossentropy: 0.0031 - val_loss: 0.0515 - val_categorical_crossentropy: 0.0515\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0031 - categorical_crossentropy: 0.0031 - val_loss: 0.0514 - val_categorical_crossentropy: 0.0514\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0031 - categorical_crossentropy: 0.0031 - val_loss: 0.0514 - val_categorical_crossentropy: 0.0514\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0030 - categorical_crossentropy: 0.0030 - val_loss: 0.0512 - val_categorical_crossentropy: 0.0512\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0030 - categorical_crossentropy: 0.0030 - val_loss: 0.0512 - val_categorical_crossentropy: 0.0512\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0030 - categorical_crossentropy: 0.0030 - val_loss: 0.0511 - val_categorical_crossentropy: 0.0511\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0029 - categorical_crossentropy: 0.0029 - val_loss: 0.0512 - val_categorical_crossentropy: 0.0512\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0029 - categorical_crossentropy: 0.0029 - val_loss: 0.0511 - val_categorical_crossentropy: 0.0511\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029 - categorical_crossentropy: 0.0029 - val_loss: 0.0509 - val_categorical_crossentropy: 0.0509\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029 - categorical_crossentropy: 0.0029 - val_loss: 0.0507 - val_categorical_crossentropy: 0.0507\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028 - categorical_crossentropy: 0.0028 - val_loss: 0.0507 - val_categorical_crossentropy: 0.0507\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028 - categorical_crossentropy: 0.0028 - val_loss: 0.0506 - val_categorical_crossentropy: 0.0506\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028 - categorical_crossentropy: 0.0028 - val_loss: 0.0505 - val_categorical_crossentropy: 0.0505\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027 - categorical_crossentropy: 0.0027 - val_loss: 0.0504 - val_categorical_crossentropy: 0.0504\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027 - categorical_crossentropy: 0.0027 - val_loss: 0.0504 - val_categorical_crossentropy: 0.0504\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027 - categorical_crossentropy: 0.0027 - val_loss: 0.0502 - val_categorical_crossentropy: 0.0502\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027 - categorical_crossentropy: 0.0027 - val_loss: 0.0501 - val_categorical_crossentropy: 0.0501\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027 - categorical_crossentropy: 0.0027 - val_loss: 0.0500 - val_categorical_crossentropy: 0.0500\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026 - categorical_crossentropy: 0.0026 - val_loss: 0.0499 - val_categorical_crossentropy: 0.0499\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026 - categorical_crossentropy: 0.0026 - val_loss: 0.0498 - val_categorical_crossentropy: 0.0498\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.0001),  metrics=['categorical_crossentropy'])\n",
    "# fit the model\n",
    "training = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('categorical_crossentropy vs Epochs')\n",
    "plt.plot(training.history['categorical_crossentropy']) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('val_categorical_crossentropy vs Epochs')\n",
    "plt.plot(training.history['val_categorical_crossentropy']) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2211 - categorical_crossentropy: 0.2211\n",
      "test loss [0.2210792899131775, 0.2210792899131775]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "    return loss\n",
    "loss = evaluate_model(model, X_test, y_test)\n",
    "print('test loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.053711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>1576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>1579</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.006836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>1580</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>1583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136720</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107420</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   margin1   margin2   margin3   margin4   margin5   margin6  \\\n",
       "0       4  0.019531  0.009766  0.078125  0.011719  0.003906  0.015625   \n",
       "1       7  0.007812  0.005859  0.064453  0.009766  0.003906  0.013672   \n",
       "2       9  0.000000  0.000000  0.001953  0.021484  0.041016  0.000000   \n",
       "3      12  0.000000  0.000000  0.009766  0.011719  0.017578  0.000000   \n",
       "4      13  0.001953  0.000000  0.015625  0.009766  0.039062  0.000000   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "589  1576  0.000000  0.000000  0.003906  0.015625  0.041016  0.000000   \n",
       "590  1577  0.000000  0.003906  0.003906  0.005859  0.017578  0.000000   \n",
       "591  1579  0.017578  0.029297  0.015625  0.013672  0.003906  0.015625   \n",
       "592  1580  0.013672  0.009766  0.060547  0.025391  0.035156  0.025391   \n",
       "593  1583  0.000000  0.117190  0.000000  0.019531  0.000000  0.136720   \n",
       "\n",
       "      margin7   margin8   margin9  ...  texture55  texture56  texture57  \\\n",
       "0    0.005859  0.000000  0.005859  ...   0.006836   0.000000   0.015625   \n",
       "1    0.007812  0.000000  0.033203  ...   0.000000   0.000000   0.006836   \n",
       "2    0.023438  0.000000  0.011719  ...   0.128910   0.000000   0.000977   \n",
       "3    0.003906  0.000000  0.003906  ...   0.012695   0.015625   0.002930   \n",
       "4    0.009766  0.000000  0.005859  ...   0.000000   0.042969   0.016602   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "589  0.017578  0.000000  0.005859  ...   0.098633   0.000000   0.004883   \n",
       "590  0.017578  0.005859  0.000000  ...   0.012695   0.004883   0.004883   \n",
       "591  0.025391  0.000000  0.000000  ...   0.073242   0.000000   0.028320   \n",
       "592  0.039062  0.000000  0.003906  ...   0.003906   0.000000   0.000977   \n",
       "593  0.001953  0.005859  0.000000  ...   0.107420   0.012695   0.016602   \n",
       "\n",
       "     texture58  texture59  texture60  texture61  texture62  texture63  \\\n",
       "0     0.000977   0.015625        0.0        0.0   0.000000   0.003906   \n",
       "1     0.001953   0.013672        0.0        0.0   0.000977   0.037109   \n",
       "2     0.000000   0.000000        0.0        0.0   0.015625   0.000000   \n",
       "3     0.036133   0.013672        0.0        0.0   0.089844   0.000000   \n",
       "4     0.010742   0.041016        0.0        0.0   0.007812   0.009766   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "589   0.000000   0.003906        0.0        0.0   0.018555   0.000000   \n",
       "590   0.002930   0.009766        0.0        0.0   0.090820   0.000000   \n",
       "591   0.000000   0.001953        0.0        0.0   0.000000   0.042969   \n",
       "592   0.000000   0.011719        0.0        0.0   0.000000   0.011719   \n",
       "593   0.000977   0.004883        0.0        0.0   0.015625   0.000000   \n",
       "\n",
       "     texture64  \n",
       "0     0.053711  \n",
       "1     0.044922  \n",
       "2     0.000000  \n",
       "3     0.008789  \n",
       "4     0.007812  \n",
       "..         ...  \n",
       "589   0.000977  \n",
       "590   0.016602  \n",
       "591   0.006836  \n",
       "592   0.018555  \n",
       "593   0.017578  \n",
       "\n",
       "[594 rows x 193 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "path = 'test.csv'\n",
    "test_df = read_csv(path)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 193)\n",
      "0.019531\n",
      "(594, 192)\n",
      "[ 1.03008102e-01 -4.89578381e-01  1.86357296e+00 -3.85267810e-01\n",
      " -5.49861318e-01 -4.52044328e-01 -7.90785284e-01 -4.19629064e-01\n",
      " -1.21437934e-01  2.56155413e-01 -7.05013499e-01  8.44298651e-01\n",
      "  7.21685644e-01 -4.30934077e-01  1.41477307e+00 -9.39750562e-02\n",
      " -1.25898538e+00  5.71652083e-02 -7.18400438e-01  2.31022229e-01\n",
      " -4.81319618e-01 -6.00640596e-01 -2.21545845e-01 -1.32325376e-01\n",
      " -7.01441819e-02 -2.55965256e-01 -4.94056343e-01  1.65648002e-01\n",
      "  5.88850723e-02  2.85993873e-01 -5.43559223e-01 -3.04492135e-01\n",
      "  3.70309809e-01 -5.17467736e-01  2.28076860e-02 -7.40273127e-01\n",
      "  2.35775311e+00  1.46253971e+00  1.26901711e+00 -1.87230134e-01\n",
      " -2.94465548e-01 -1.09072028e+00  1.32612886e-01  1.11962601e+00\n",
      " -7.67192204e-01 -6.39964479e-01 -8.08408393e-02  1.33838501e+00\n",
      " -5.39153280e-01 -1.31765075e-01  1.90848182e-01 -1.04451956e-01\n",
      " -6.97875307e-01 -3.79038738e-01 -4.91635584e-01 -6.72590648e-01\n",
      " -3.05715785e-01 -8.85164037e-01  7.45717689e-01 -9.56002885e-01\n",
      " -5.99831610e-01 -4.66368964e-01  1.38560196e+00 -4.57653360e-01\n",
      "  1.57982371e-01  4.15960203e-01  7.08554299e-01  1.01803742e+00\n",
      "  1.37957918e+00  1.73445920e+00  2.02770649e+00  2.33407405e+00\n",
      "  2.59908735e+00  2.84056830e+00  3.05637819e+00  3.27922321e+00\n",
      "  3.38549216e+00  3.01670612e+00  2.65960652e+00  2.35189716e+00\n",
      "  2.09806364e+00  1.91031450e+00  1.81656911e+00  1.69916424e+00\n",
      "  1.60060419e+00  1.46132104e+00  1.29928364e+00  1.12825256e+00\n",
      "  9.04294422e-01  7.07895198e-01  4.89432965e-01  2.52199293e-01\n",
      "  3.80225324e-02 -6.24201553e-02 -1.02977194e-01 -9.92296186e-02\n",
      " -7.19335094e-03  1.68321336e-01  4.45044275e-01  7.92947538e-01\n",
      "  1.15862156e+00  1.51195714e+00  1.87396530e+00  2.17480760e+00\n",
      "  2.41535824e+00  2.56281996e+00  2.75740677e+00  2.83030659e+00\n",
      "  2.78140056e+00  2.70759789e+00  2.59333528e+00  2.37254572e+00\n",
      "  2.13582255e+00  1.92567819e+00  1.77199657e+00  1.60765134e+00\n",
      "  1.51679642e+00  1.39340643e+00  1.22113506e+00  1.00907967e+00\n",
      "  7.75332758e-01  5.38604492e-01  3.90055863e-01  2.55635017e-01\n",
      "  1.27218977e-01  7.88581609e-02  5.06743769e-02  1.31080247e-02\n",
      "  1.87607146e+00  8.43136087e-02  1.01081048e-01 -4.68325088e-01\n",
      " -4.12831709e-01  5.60284666e-01  1.63063690e+00  3.73539221e-01\n",
      "  1.06600896e+00 -2.97328369e-01 -3.58899908e-01 -3.59091012e-01\n",
      " -7.23829589e-02 -2.21933132e-01 -1.92795730e-01 -3.89100056e-01\n",
      "  7.16901549e-02 -3.85384988e-01  1.06606666e-03  4.86229091e-01\n",
      " -2.68624270e-01 -5.67266881e-01  3.20684207e-01 -5.58981844e-01\n",
      " -3.41326519e-01 -5.40346356e-01 -2.22327406e-01 -4.57267809e-01\n",
      "  9.46102328e-01  9.65613411e-01  8.15971801e-01 -3.88040903e-01\n",
      " -3.86231275e-01  9.95729601e-01  1.02042472e-01 -2.43422473e-01\n",
      " -3.45600091e-01  1.08093207e+00  3.00926295e-01  2.71264629e-01\n",
      " -3.77648689e-01 -4.57317706e-01 -1.93058394e-01 -1.03118155e-01\n",
      " -1.32794448e-01  4.42435653e-01  3.99893250e-01 -5.71735079e-01\n",
      "  2.63311938e-01  2.44509927e-02 -4.09705479e-01 -5.16567159e-01\n",
      " -6.45579163e-01 -2.66847602e-01 -4.54119188e-01 -2.58105155e-01\n",
      " -3.79373232e-02 -4.04737488e-01 -3.57760564e-02 -2.38210885e-01\n",
      " -2.05724818e-01 -4.96437742e-01 -3.93676127e-01  1.46579776e+00]\n"
     ]
    }
   ],
   "source": [
    "# split into input and output columns\n",
    "import numpy as np\n",
    "test_X = test_df.values[:, 0:]\n",
    "print(test_X.shape)\n",
    "print(test_X[0][1])\n",
    "test_X = test_X.astype('float64') # ensure all data are floating point values\n",
    "x_test = test_X[:, 1:]\n",
    "x_test = scaler.transform(x_test)\n",
    "print(x_test.shape)\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "import pandas as pd  \n",
    "def eval_model(model, X_test, class_names, ids):\n",
    "    y_pred = model.predict(X_test)\n",
    "    k_df = pd.DataFrame(y_pred, columns=class_names)\n",
    "    k_df['id'] = ids\n",
    "    return k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>Acer_Saccharinum</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.076913e-05</td>\n",
       "      <td>1.241548e-04</td>\n",
       "      <td>5.839184e-07</td>\n",
       "      <td>5.129814e-04</td>\n",
       "      <td>3.858877e-05</td>\n",
       "      <td>6.333100e-05</td>\n",
       "      <td>2.231470e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.338254e-05</td>\n",
       "      <td>1.274210e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>8.509530e-05</td>\n",
       "      <td>4.473661e-05</td>\n",
       "      <td>3.721268e-06</td>\n",
       "      <td>4.469444e-05</td>\n",
       "      <td>6.771128e-06</td>\n",
       "      <td>2.191472e-05</td>\n",
       "      <td>4.454155e-07</td>\n",
       "      <td>1.326077e-03</td>\n",
       "      <td>4.019842e-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.269474e-07</td>\n",
       "      <td>2.741940e-07</td>\n",
       "      <td>2.271056e-06</td>\n",
       "      <td>9.315438e-05</td>\n",
       "      <td>1.319451e-07</td>\n",
       "      <td>2.492812e-06</td>\n",
       "      <td>1.743945e-04</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.144991e-07</td>\n",
       "      <td>6.319500e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.189719e-06</td>\n",
       "      <td>2.539464e-07</td>\n",
       "      <td>3.179580e-08</td>\n",
       "      <td>9.717258e-09</td>\n",
       "      <td>1.185483e-04</td>\n",
       "      <td>1.080897e-05</td>\n",
       "      <td>1.644523e-05</td>\n",
       "      <td>2.171818e-06</td>\n",
       "      <td>2.735979e-07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.285405e-05</td>\n",
       "      <td>9.867401e-01</td>\n",
       "      <td>1.064108e-05</td>\n",
       "      <td>2.235249e-06</td>\n",
       "      <td>6.851715e-03</td>\n",
       "      <td>2.366688e-05</td>\n",
       "      <td>4.107446e-06</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>6.003045e-04</td>\n",
       "      <td>6.432307e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.125725e-06</td>\n",
       "      <td>6.503007e-06</td>\n",
       "      <td>1.642632e-06</td>\n",
       "      <td>6.421500e-07</td>\n",
       "      <td>1.376450e-05</td>\n",
       "      <td>5.981086e-05</td>\n",
       "      <td>1.030409e-07</td>\n",
       "      <td>3.317210e-06</td>\n",
       "      <td>4.005594e-04</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.252050e-05</td>\n",
       "      <td>7.985756e-03</td>\n",
       "      <td>3.536421e-05</td>\n",
       "      <td>1.630194e-05</td>\n",
       "      <td>1.999937e-05</td>\n",
       "      <td>2.457319e-05</td>\n",
       "      <td>4.587710e-04</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>4.404612e-04</td>\n",
       "      <td>2.135462e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.273950e-05</td>\n",
       "      <td>2.257638e-05</td>\n",
       "      <td>6.326851e-06</td>\n",
       "      <td>1.349006e-05</td>\n",
       "      <td>2.510913e-04</td>\n",
       "      <td>1.716821e-03</td>\n",
       "      <td>7.034958e-05</td>\n",
       "      <td>5.117502e-06</td>\n",
       "      <td>4.778965e-04</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.658356e-05</td>\n",
       "      <td>1.886167e-04</td>\n",
       "      <td>7.964876e-06</td>\n",
       "      <td>2.190619e-06</td>\n",
       "      <td>6.439604e-05</td>\n",
       "      <td>4.104415e-06</td>\n",
       "      <td>1.461819e-04</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>6.534347e-03</td>\n",
       "      <td>2.750252e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>5.587980e-06</td>\n",
       "      <td>1.790019e-04</td>\n",
       "      <td>3.727838e-05</td>\n",
       "      <td>1.771581e-03</td>\n",
       "      <td>1.335384e-03</td>\n",
       "      <td>1.573864e-02</td>\n",
       "      <td>2.548704e-05</td>\n",
       "      <td>7.239965e-05</td>\n",
       "      <td>5.497418e-06</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2.407753e-05</td>\n",
       "      <td>9.962231e-01</td>\n",
       "      <td>2.566853e-05</td>\n",
       "      <td>9.373770e-07</td>\n",
       "      <td>1.286212e-03</td>\n",
       "      <td>1.796198e-06</td>\n",
       "      <td>5.262132e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.585312e-04</td>\n",
       "      <td>1.119660e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.965167e-06</td>\n",
       "      <td>2.175260e-06</td>\n",
       "      <td>1.220618e-06</td>\n",
       "      <td>2.088549e-07</td>\n",
       "      <td>5.008652e-06</td>\n",
       "      <td>1.183893e-04</td>\n",
       "      <td>1.766233e-07</td>\n",
       "      <td>1.462596e-06</td>\n",
       "      <td>2.977544e-04</td>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>4.750816e-05</td>\n",
       "      <td>7.735743e-06</td>\n",
       "      <td>2.951737e-07</td>\n",
       "      <td>4.721642e-05</td>\n",
       "      <td>3.417423e-07</td>\n",
       "      <td>2.188801e-07</td>\n",
       "      <td>1.333265e-06</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>7.052679e-04</td>\n",
       "      <td>1.803344e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>6.055191e-07</td>\n",
       "      <td>3.577938e-04</td>\n",
       "      <td>9.227833e-07</td>\n",
       "      <td>4.275374e-04</td>\n",
       "      <td>1.234014e-04</td>\n",
       "      <td>1.012481e-05</td>\n",
       "      <td>1.481107e-07</td>\n",
       "      <td>5.357485e-07</td>\n",
       "      <td>1.588114e-04</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>1.955685e-05</td>\n",
       "      <td>4.564098e-06</td>\n",
       "      <td>4.375251e-07</td>\n",
       "      <td>2.867774e-07</td>\n",
       "      <td>9.415805e-06</td>\n",
       "      <td>2.197509e-05</td>\n",
       "      <td>4.808410e-07</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>4.585994e-07</td>\n",
       "      <td>2.291798e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.716148e-08</td>\n",
       "      <td>2.666313e-06</td>\n",
       "      <td>8.352768e-06</td>\n",
       "      <td>7.491772e-06</td>\n",
       "      <td>8.475816e-09</td>\n",
       "      <td>2.708916e-08</td>\n",
       "      <td>2.051024e-06</td>\n",
       "      <td>1.888854e-06</td>\n",
       "      <td>6.652789e-05</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>2.422213e-04</td>\n",
       "      <td>2.059631e-04</td>\n",
       "      <td>2.660776e-03</td>\n",
       "      <td>8.338656e-05</td>\n",
       "      <td>3.056949e-04</td>\n",
       "      <td>1.060403e-04</td>\n",
       "      <td>1.889601e-03</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>3.910348e-05</td>\n",
       "      <td>1.415417e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.172907e-03</td>\n",
       "      <td>1.828759e-05</td>\n",
       "      <td>1.309958e-03</td>\n",
       "      <td>5.321371e-05</td>\n",
       "      <td>5.572961e-04</td>\n",
       "      <td>1.354813e-04</td>\n",
       "      <td>1.651493e-04</td>\n",
       "      <td>3.464843e-05</td>\n",
       "      <td>2.540427e-05</td>\n",
       "      <td>1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>9.366958e-08</td>\n",
       "      <td>1.294507e-05</td>\n",
       "      <td>1.974676e-05</td>\n",
       "      <td>2.133704e-06</td>\n",
       "      <td>5.753562e-06</td>\n",
       "      <td>2.165799e-04</td>\n",
       "      <td>2.109975e-05</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1.927951e-05</td>\n",
       "      <td>1.533204e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.278665e-07</td>\n",
       "      <td>2.115107e-06</td>\n",
       "      <td>4.110850e-06</td>\n",
       "      <td>1.760401e-06</td>\n",
       "      <td>1.996905e-05</td>\n",
       "      <td>2.051642e-06</td>\n",
       "      <td>3.510087e-07</td>\n",
       "      <td>1.605371e-07</td>\n",
       "      <td>1.586182e-05</td>\n",
       "      <td>1583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Acer_Capillipes  Acer_Circinatum     Acer_Mono   Acer_Opalus  \\\n",
       "0       4.076913e-05     1.241548e-04  5.839184e-07  5.129814e-04   \n",
       "1       2.269474e-07     2.741940e-07  2.271056e-06  9.315438e-05   \n",
       "2       1.285405e-05     9.867401e-01  1.064108e-05  2.235249e-06   \n",
       "3       1.252050e-05     7.985756e-03  3.536421e-05  1.630194e-05   \n",
       "4       7.658356e-05     1.886167e-04  7.964876e-06  2.190619e-06   \n",
       "..               ...              ...           ...           ...   \n",
       "589     2.407753e-05     9.962231e-01  2.566853e-05  9.373770e-07   \n",
       "590     4.750816e-05     7.735743e-06  2.951737e-07  4.721642e-05   \n",
       "591     1.955685e-05     4.564098e-06  4.375251e-07  2.867774e-07   \n",
       "592     2.422213e-04     2.059631e-04  2.660776e-03  8.338656e-05   \n",
       "593     9.366958e-08     1.294507e-05  1.974676e-05  2.133704e-06   \n",
       "\n",
       "     Acer_Palmatum   Acer_Pictum  Acer_Platanoids  Acer_Rubrum  \\\n",
       "0     3.858877e-05  6.333100e-05     2.231470e-06     0.000011   \n",
       "1     1.319451e-07  2.492812e-06     1.743945e-04     0.000002   \n",
       "2     6.851715e-03  2.366688e-05     4.107446e-06     0.000086   \n",
       "3     1.999937e-05  2.457319e-05     4.587710e-04     0.000058   \n",
       "4     6.439604e-05  4.104415e-06     1.461819e-04     0.000031   \n",
       "..             ...           ...              ...          ...   \n",
       "589   1.286212e-03  1.796198e-06     5.262132e-07     0.000014   \n",
       "590   3.417423e-07  2.188801e-07     1.333265e-06     0.000053   \n",
       "591   9.415805e-06  2.197509e-05     4.808410e-07     0.000021   \n",
       "592   3.056949e-04  1.060403e-04     1.889601e-03     0.000159   \n",
       "593   5.753562e-06  2.165799e-04     2.109975e-05     0.000032   \n",
       "\n",
       "     Acer_Rufinerve  Acer_Saccharinum  ...  Salix_Intergra   Sorbus_Aria  \\\n",
       "0      1.338254e-05      1.274210e-04  ...    8.509530e-05  4.473661e-05   \n",
       "1      6.144991e-07      6.319500e-07  ...    4.189719e-06  2.539464e-07   \n",
       "2      6.003045e-04      6.432307e-05  ...    7.125725e-06  6.503007e-06   \n",
       "3      4.404612e-04      2.135462e-04  ...    1.273950e-05  2.257638e-05   \n",
       "4      6.534347e-03      2.750252e-04  ...    5.587980e-06  1.790019e-04   \n",
       "..              ...               ...  ...             ...           ...   \n",
       "589    1.585312e-04      1.119660e-05  ...    7.965167e-06  2.175260e-06   \n",
       "590    7.052679e-04      1.803344e-07  ...    6.055191e-07  3.577938e-04   \n",
       "591    4.585994e-07      2.291798e-05  ...    3.716148e-08  2.666313e-06   \n",
       "592    3.910348e-05      1.415417e-06  ...    2.172907e-03  1.828759e-05   \n",
       "593    1.927951e-05      1.533204e-06  ...    5.278665e-07  2.115107e-06   \n",
       "\n",
       "     Tilia_Oliveri  Tilia_Platyphyllos  Tilia_Tomentosa  Ulmus_Bergmanniana  \\\n",
       "0     3.721268e-06        4.469444e-05     6.771128e-06        2.191472e-05   \n",
       "1     3.179580e-08        9.717258e-09     1.185483e-04        1.080897e-05   \n",
       "2     1.642632e-06        6.421500e-07     1.376450e-05        5.981086e-05   \n",
       "3     6.326851e-06        1.349006e-05     2.510913e-04        1.716821e-03   \n",
       "4     3.727838e-05        1.771581e-03     1.335384e-03        1.573864e-02   \n",
       "..             ...                 ...              ...                 ...   \n",
       "589   1.220618e-06        2.088549e-07     5.008652e-06        1.183893e-04   \n",
       "590   9.227833e-07        4.275374e-04     1.234014e-04        1.012481e-05   \n",
       "591   8.352768e-06        7.491772e-06     8.475816e-09        2.708916e-08   \n",
       "592   1.309958e-03        5.321371e-05     5.572961e-04        1.354813e-04   \n",
       "593   4.110850e-06        1.760401e-06     1.996905e-05        2.051642e-06   \n",
       "\n",
       "     Viburnum_Tinus  Viburnum_x_Rhytidophylloides  Zelkova_Serrata    id  \n",
       "0      4.454155e-07                  1.326077e-03     4.019842e-06     4  \n",
       "1      1.644523e-05                  2.171818e-06     2.735979e-07     7  \n",
       "2      1.030409e-07                  3.317210e-06     4.005594e-04     9  \n",
       "3      7.034958e-05                  5.117502e-06     4.778965e-04    12  \n",
       "4      2.548704e-05                  7.239965e-05     5.497418e-06    13  \n",
       "..              ...                           ...              ...   ...  \n",
       "589    1.766233e-07                  1.462596e-06     2.977544e-04  1576  \n",
       "590    1.481107e-07                  5.357485e-07     1.588114e-04  1577  \n",
       "591    2.051024e-06                  1.888854e-06     6.652789e-05  1579  \n",
       "592    1.651493e-04                  3.464843e-05     2.540427e-05  1580  \n",
       "593    3.510087e-07                  1.605371e-07     1.586182e-05  1583  \n",
       "\n",
       "[594 rows x 100 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_df = eval_model(model, x_test, sorted(df['species'].unique()), test_df['id'].values)\n",
    "k_df.to_csv(\"test_results.csv\", index=False)\n",
    "k_df"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the score\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
